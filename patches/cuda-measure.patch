diff --git a/Makefile b/Makefile
index 63e15e6..8ec365a 100644
--- a/Makefile
+++ b/Makefile
@@ -1,8 +1,9 @@
-GPU=0
+GPU=1
 CUDNN=0
-OPENCV=0
+OPENCV=1
 OPENMP=0
 DEBUG=0
+BENCHMARK=1
 
 ARCH= -gencode arch=compute_30,code=sm_30 \
       -gencode arch=compute_35,code=sm_35 \
@@ -58,6 +59,11 @@ CFLAGS+= -DCUDNN
 LDFLAGS+= -lcudnn
 endif
 
+ifeq ($(BENCHMARK), 1) 
+COMMON+= -DBENCHMARK
+CFLAGS+= -DBENCHMARK
+endif
+
 OBJ=gemm.o utils.o cuda.o deconvolutional_layer.o convolutional_layer.o list.o image.o activations.o im2col.o col2im.o blas.o crop_layer.o dropout_layer.o maxpool_layer.o softmax_layer.o data.o matrix.o network.o connected_layer.o cost_layer.o parser.o option_list.o detection_layer.o route_layer.o upsample_layer.o box.o normalization_layer.o avgpool_layer.o layer.o local_layer.o shortcut_layer.o logistic_layer.o activation_layer.o rnn_layer.o gru_layer.o crnn_layer.o demo.o batchnorm_layer.o region_layer.o reorg_layer.o tree.o  lstm_layer.o l2norm_layer.o yolo_layer.o iseg_layer.o image_opencv.o
 EXECOBJA=captcha.o lsd.o super.o art.o tag.o cifar.o go.o rnn.o segmenter.o regressor.o classifier.o coco.o yolo.o detector.o nightmare.o instance-segmenter.o darknet.o
 ifeq ($(GPU), 1) 
diff --git a/examples/cifar.c b/examples/cifar.c
index a5f5f24..47d52a7 100644
--- a/examples/cifar.c
+++ b/examples/cifar.c
@@ -34,6 +34,9 @@ void train_cifar(char *cfgfile, char *weightfile)
             sprintf(buff, "%s/%s.backup",backup_directory,base);
             save_weights(net, buff);
         }
+#ifdef BENCHMARK
+        break;
+#endif
     }
     char buff[256];
     sprintf(buff, "%s/%s.weights", backup_directory, base);
diff --git a/examples/detector.c b/examples/detector.c
index 318f7fb..b8fa5b4 100644
--- a/examples/detector.c
+++ b/examples/detector.c
@@ -30,7 +30,7 @@ void train_detector(char *datacfg, char *cfgfile, char *weightfile, int *gpus, i
     network *net = nets[0];
 
     int imgs = net->batch * net->subdivisions * ngpus;
-    printf("Learning Rate: %g, Momentum: %g, Decay: %g\n", net->learning_rate, net->momentum, net->decay);
+    //printf("Learning Rate: %g, Momentum: %g, Decay: %g\n", net->learning_rate, net->momentum, net->decay);
     data train, buffer;
 
     layer l = net->layers[net->n - 1];
@@ -56,16 +56,19 @@ void train_detector(char *datacfg, char *cfgfile, char *weightfile, int *gpus, i
     args.threads = 64;
 
     pthread_t load_thread = load_data(args);
-    double time;
+    double time=what_time_is_it_now();
     int count = 0;
     //while(i*imgs < N*120){
     while(get_current_batch(net) < net->max_batches){
         if(l.random && count++%10 == 0){
-            printf("Resizing\n");
+            //printf("Resizing\n");
             int dim = (rand() % 10 + 10) * 32;
+#ifdef BENCHMARK
+            dim = 608;
+#endif
             if (get_current_batch(net)+200 > net->max_batches) dim = 608;
             //int dim = (rand() % 4 + 16) * 32;
-            printf("%d\n", dim);
+            //printf("%d\n", dim);
             args.w = dim;
             args.h = dim;
 
@@ -80,7 +83,7 @@ void train_detector(char *datacfg, char *cfgfile, char *weightfile, int *gpus, i
             }
             net = nets[0];
         }
-        time=what_time_is_it_now();
+        //time=what_time_is_it_now();
         pthread_join(load_thread, 0);
         train = buffer;
         load_thread = load_data(args);
@@ -109,9 +112,9 @@ void train_detector(char *datacfg, char *cfgfile, char *weightfile, int *gpus, i
            }
          */
 
-        printf("Loaded: %lf seconds\n", what_time_is_it_now()-time);
+        //printf("Loaded: %lf seconds\n", what_time_is_it_now()-time);
 
-        time=what_time_is_it_now();
+        //time=what_time_is_it_now();
         float loss = 0;
 #ifdef GPU
         if(ngpus == 1){
@@ -126,7 +129,8 @@ void train_detector(char *datacfg, char *cfgfile, char *weightfile, int *gpus, i
         avg_loss = avg_loss*.9 + loss*.1;
 
         i = get_current_batch(net);
-        printf("%ld: %f, %f avg, %f rate, %lf seconds, %d images\n", get_current_batch(net), loss, avg_loss, get_current_rate(net), what_time_is_it_now()-time, i*imgs);
+        //printf("%ld: %f, %f avg, %f rate, %lf seconds, %d images\n", get_current_batch(net), loss, avg_loss, get_current_rate(net), what_time_is_it_now()-time, i*imgs);
+        printf("%lf\t%f\n", what_time_is_it_now()-time, loss);
         if(i%100==0){
 #ifdef GPU
             if(ngpus != 1) sync_nets(nets, ngpus, 0);
@@ -144,12 +148,15 @@ void train_detector(char *datacfg, char *cfgfile, char *weightfile, int *gpus, i
             save_weights(net, buff);
         }
         free_data(train);
+#ifdef BENCHMARK
+        break;
+#endif
     }
 #ifdef GPU
     if(ngpus != 1) sync_nets(nets, ngpus, 0);
 #endif
     char buff[256];
-    sprintf(buff, "%s/%s_final.weights", backup_directory, base);
+    //sprintf(buff, "%s/%s_final.weights", backup_directory, base);
     save_weights(net, buff);
 }
 
diff --git a/src/activation_kernels.cu b/src/activation_kernels.cu
index 4dc5804..59ea89c 100644
--- a/src/activation_kernels.cu
+++ b/src/activation_kernels.cu
@@ -162,7 +162,16 @@ __global__ void binary_gradient_array_kernel(float *x, float *dy, int n, int s,
 
 extern "C" void binary_gradient_array_gpu(float *x, float *dx, int n, int size, BINARY_ACTIVATION a, float *y) 
 {
+#ifdef BENCHMARK
+    clock_t t;
+    t = clock();
+#endif
     binary_gradient_array_kernel<<<cuda_gridsize(n/2), BLOCK>>>(x, dx, n/2, size, a, y);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "binary_gradient_array_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 __global__ void binary_activate_array_kernel(float *x, int n, int s, BINARY_ACTIVATION a, float *y)
@@ -177,7 +186,16 @@ __global__ void binary_activate_array_kernel(float *x, int n, int s, BINARY_ACTI
 
 extern "C" void binary_activate_array_gpu(float *x, int n, int size, BINARY_ACTIVATION a, float *y) 
 {
+#ifdef BENCHMARK
+    clock_t t;
+    t = clock();
+#endif
     binary_activate_array_kernel<<<cuda_gridsize(n/2), BLOCK>>>(x, n/2, size, a, y);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "binary_activate_array_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -195,12 +213,30 @@ __global__ void gradient_array_kernel(float *x, int n, ACTIVATION a, float *delt
 
 extern "C" void activate_array_gpu(float *x, int n, ACTIVATION a) 
 {
+#ifdef BENCHMARK
+    clock_t t;
+    t = clock();
+#endif
     activate_array_kernel<<<cuda_gridsize(n), BLOCK>>>(x, n, a);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "activate_array_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
 extern "C" void gradient_array_gpu(float *x, int n, ACTIVATION a, float *delta) 
 {
+#ifdef BENCHMARK
+    clock_t t;
+    t = clock();
+#endif
     gradient_array_kernel<<<cuda_gridsize(n), BLOCK>>>(x, n, a, delta);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "gradient_array_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
diff --git a/src/avgpool_layer_kernels.cu b/src/avgpool_layer_kernels.cu
index a7eca3a..c1da738 100644
--- a/src/avgpool_layer_kernels.cu
+++ b/src/avgpool_layer_kernels.cu
@@ -47,7 +47,16 @@ extern "C" void forward_avgpool_layer_gpu(avgpool_layer layer, network net)
 {
     size_t n = layer.c*layer.batch;
 
+#ifdef BENCHMARK
+    clock_t t;
+    t = clock();
+#endif
     forward_avgpool_layer_kernel<<<cuda_gridsize(n), BLOCK>>>(n, layer.w, layer.h, layer.c, net.input_gpu, layer.output_gpu);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "forward_avgpool_layer_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -55,7 +64,15 @@ extern "C" void backward_avgpool_layer_gpu(avgpool_layer layer, network net)
 {
     size_t n = layer.c*layer.batch;
 
+#ifdef BENCHMARK
+    clock_t t;
+    t = clock();
+#endif
     backward_avgpool_layer_kernel<<<cuda_gridsize(n), BLOCK>>>(n, layer.w, layer.h, layer.c, net.delta_gpu, layer.delta_gpu);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "backward_avgpool_layer_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
-
diff --git a/src/blas_kernels.cu b/src/blas_kernels.cu
index 47e8217..68dab21 100644
--- a/src/blas_kernels.cu
+++ b/src/blas_kernels.cu
@@ -7,6 +7,7 @@ extern "C" {
 #include "blas.h"
 #include "cuda.h"
 #include "utils.h"
+clock_t t;
 }
 
 __global__ void scale_bias_kernel(float *output, float *biases, int n, int size)
@@ -18,12 +19,19 @@ __global__ void scale_bias_kernel(float *output, float *biases, int n, int size)
     if(offset < size) output[(batch*n+filter)*size + offset] *= biases[filter];
 }
 
-void scale_bias_gpu(float *output, float *biases, int batch, int n, int size)
+extern "C" void scale_bias_gpu(float *output, float *biases, int batch, int n, int size)
 {
     dim3 dimGrid((size-1)/BLOCK + 1, n, batch);
     dim3 dimBlock(BLOCK, 1, 1);
-
+#ifdef BENCHMARK
+    t = clock();
+#endif
     scale_bias_kernel<<<dimGrid, dimBlock>>>(output, biases, n, size);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "scale_bias_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -47,9 +55,17 @@ __global__ void backward_scale_kernel(float *x_norm, float *delta, int batch, in
     }
 }
 
-void backward_scale_gpu(float *x_norm, float *delta, int batch, int n, int size, float *scale_updates)
+extern "C" void backward_scale_gpu(float *x_norm, float *delta, int batch, int n, int size, float *scale_updates)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     backward_scale_kernel<<<n, BLOCK>>>(x_norm, delta, batch, n, size, scale_updates);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "backward_scale_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -66,11 +82,18 @@ __global__ void add_bias_kernel(float *output, float *biases, int batch, int n,
     output[(k*n+j)*size + i] += biases[j];
 }
 
-void add_bias_gpu(float *output, float *biases, int batch, int n, int size)
+extern "C" void add_bias_gpu(float *output, float *biases, int batch, int n, int size)
 {
     int num = n*size*batch;
-
+#ifdef BENCHMARK
+    t = clock();
+#endif
     add_bias_kernel<<<cuda_gridsize(num), BLOCK>>>(output, biases, batch, n, size);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "add_bias_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -107,12 +130,30 @@ __global__ void backward_bias_kernel(float *bias_updates, float *delta, int batc
     }
 }
 
-void backward_bias_gpu(float *bias_updates, float *delta, int batch, int n, int size)
+extern "C" void backward_bias_gpu(float *bias_updates, float *delta, int batch, int n, int size)
 {
     if(size == 1){
+#ifdef BENCHMARK
+    clock_t tc;
+    tc = clock();
+#endif
         backward_bias_conn_kernel<<<cuda_gridsize(n), BLOCK>>>(bias_updates, delta, batch, n);
+#ifdef BENCHMARK
+    tc = clock() - tc;
+    double time_taken = ((double)tc);
+    printf("%s\t%d\n", "backward_bias_conn_kernel", (int)time_taken);
+#endif
     }else{
+#ifdef BENCHMARK
+    clock_t tm;
+    tm = clock();
+#endif
         backward_bias_kernel<<<n, BLOCK>>>(bias_updates, delta, batch, n, size);
+#ifdef BENCHMARK
+    tm = clock() - tm;
+    double time_taken = ((double)tm);
+    printf("%s\t%d\n", "backward_bias_kernel", (int)time_taken);
+#endif
     }
     check_error(cudaPeekAtLastError());
 }
@@ -154,7 +195,15 @@ __global__ void dot_kernel(float *output, float scale, int batch, int n, int siz
 
 void dot_error_gpu(layer l)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     dot_kernel<<<cuda_gridsize(l.n*l.n), BLOCK>>>(l.output_gpu, l.dot, l.batch, l.n, l.out_w * l.out_h, l.delta_gpu);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "adam_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 */
@@ -173,7 +222,15 @@ __global__ void adam_kernel(int N, float *x, float *m, float *v, float B1, float
 
 extern "C" void adam_gpu(int n, float *x, float *m, float *v, float B1, float B2, float rate, float eps, int t)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     adam_kernel<<<cuda_gridsize(n), BLOCK>>>(n, x, m, v, B1, B2, rate, eps, t);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "adam_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -212,7 +269,15 @@ __global__ void normalize_delta_kernel(int N, float *x, float *mean, float *vari
 extern "C" void normalize_delta_gpu(float *x, float *mean, float *variance, float *mean_delta, float *variance_delta, int batch, int filters, int spatial, float *delta)
 {
     size_t N = batch*filters*spatial;
+#ifdef BENCHMARK
+    t = clock();
+#endif
     normalize_delta_kernel<<<cuda_gridsize(N), BLOCK>>>(N, x, mean, variance, mean_delta, variance_delta, batch, filters, spatial, delta);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "normalize_delta_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -319,19 +384,43 @@ __global__ void mean_delta_kernel(float *delta, float *variance, int batch, int
 
 extern "C" void mean_delta_gpu(float *delta, float *variance, int batch, int filters, int spatial, float *mean_delta)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     mean_delta_kernel<<<cuda_gridsize(filters), BLOCK>>>(delta, variance, batch, filters, spatial, mean_delta);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "mean_delta_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
 extern "C" void fast_mean_delta_gpu(float *delta, float *variance, int batch, int filters, int spatial, float *mean_delta)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     fast_mean_delta_kernel<<<filters, BLOCK>>>(delta, variance, batch, filters, spatial, mean_delta);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "fast_mean_delta_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
 extern "C" void fast_variance_delta_gpu(float *x, float *delta, float *mean, float *variance, int batch, int filters, int spatial, float *variance_delta)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     fast_variance_delta_kernel<<<filters, BLOCK>>>(x, delta, mean, variance, batch, filters, spatial, variance_delta);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "fast_variance_delta_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -465,7 +554,15 @@ __global__ void mul_kernel(int N, float *X, int INCX, float *Y, int INCY)
 extern "C" void normalize_gpu(float *x, float *mean, float *variance, int batch, int filters, int spatial)
 {
     size_t N = batch*filters*spatial;
+#ifdef BENCHMARK
+    t = clock();
+#endif
     normalize_kernel<<<cuda_gridsize(N), BLOCK>>>(N, x, mean, variance, batch, filters, spatial);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "normalize_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -494,7 +591,15 @@ __global__ void l2norm_kernel(int N, float *x, float *dx, int batch, int filters
 extern "C" void l2normalize_gpu(float *x, float *dx, int batch, int filters, int spatial)
 {
     size_t N = batch*spatial;
+#ifdef BENCHMARK
+    t = clock();
+#endif
     l2norm_kernel<<<cuda_gridsize(N), BLOCK>>>(N, x, dx, batch, filters, spatial);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "l2norm_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -559,26 +664,58 @@ __global__ void  fast_variance_kernel(float *x, float *mean, int batch, int filt
 
 extern "C" void fast_mean_gpu(float *x, int batch, int filters, int spatial, float *mean)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     fast_mean_kernel<<<filters, BLOCK>>>(x, batch, filters, spatial, mean);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "fast_mean_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
 extern "C" void fast_variance_gpu(float *x, float *mean, int batch, int filters, int spatial, float *variance)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     fast_variance_kernel<<<filters, BLOCK>>>(x, mean, batch, filters, spatial, variance);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "fast_variance_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
 
 extern "C" void mean_gpu(float *x, int batch, int filters, int spatial, float *mean)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     mean_kernel<<<cuda_gridsize(filters), BLOCK>>>(x, batch, filters, spatial, mean);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "mean_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
 extern "C" void variance_gpu(float *x, float *mean, int batch, int filters, int spatial, float *variance)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     variance_kernel<<<cuda_gridsize(filters), BLOCK>>>(x, mean, batch, filters, spatial, variance);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "variance_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -589,13 +726,29 @@ extern "C" void axpy_gpu(int N, float ALPHA, float * X, int INCX, float * Y, int
 
 extern "C" void pow_gpu(int N, float ALPHA, float * X, int INCX, float * Y, int INCY)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     pow_kernel<<<cuda_gridsize(N), BLOCK>>>(N, ALPHA, X, INCX, Y, INCY);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "pow_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
 extern "C" void axpy_gpu_offset(int N, float ALPHA, float * X, int OFFX, int INCX, float * Y, int OFFY, int INCY)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     axpy_kernel<<<cuda_gridsize(N), BLOCK>>>(N, ALPHA, X, OFFX, INCX, Y, OFFY, INCY);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "axpy_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -606,13 +759,29 @@ extern "C" void copy_gpu(int N, float * X, int INCX, float * Y, int INCY)
 
 extern "C" void mul_gpu(int N, float * X, int INCX, float * Y, int INCY)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     mul_kernel<<<cuda_gridsize(N), BLOCK>>>(N, X, INCX, Y, INCY);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "mul_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
 extern "C" void copy_gpu_offset(int N, float * X, int OFFX, int INCX, float * Y, int OFFY, int INCY)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     copy_kernel<<<cuda_gridsize(N), BLOCK>>>(N, X, OFFX, INCX, Y, OFFY, INCY);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "copy_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -636,14 +805,30 @@ __global__ void flatten_kernel(int N, float *x, int spatial, int layers, int bat
 extern "C" void flatten_gpu(float *x, int spatial, int layers, int batch, int forward, float *out)
 {
     int size = spatial*batch*layers;
+#ifdef BENCHMARK
+    t = clock();
+#endif
     flatten_kernel<<<cuda_gridsize(size), BLOCK>>>(size, x, spatial, layers, batch, forward, out);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "flatten_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
 extern "C" void reorg_gpu(float *x, int w, int h, int c, int batch, int stride, int forward, float *out)
 {
     int size = w*h*c*batch;
+#ifdef BENCHMARK
+    t = clock();
+#endif
     reorg_kernel<<<cuda_gridsize(size), BLOCK>>>(size, x, w, h, c, batch, stride, forward, out);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "reorg_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -655,7 +840,15 @@ __global__ void mask_kernel(int n,  float *x, float mask_num, float *mask, float
 
 extern "C" void mask_gpu(int N, float * X, float mask_num, float * mask, float val)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     mask_kernel<<<cuda_gridsize(N), BLOCK>>>(N, X, mask_num, mask, val);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "mask_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -667,44 +860,100 @@ __global__ void scale_mask_kernel(int n,  float *x, float mask_num, float *mask,
 
 extern "C" void scale_mask_gpu(int N, float * X, float mask_num, float * mask, float scale)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     scale_mask_kernel<<<cuda_gridsize(N), BLOCK>>>(N, X, mask_num, mask, scale);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "scale_mask_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
 extern "C" void const_gpu(int N, float ALPHA, float * X, int INCX)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     const_kernel<<<cuda_gridsize(N), BLOCK>>>(N, ALPHA, X, INCX);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "const_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
 extern "C" void constrain_gpu(int N, float ALPHA, float * X, int INCX)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     constrain_kernel<<<cuda_gridsize(N), BLOCK>>>(N, ALPHA, X, INCX);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "constrain_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
 
 extern "C" void add_gpu(int N, float ALPHA, float * X, int INCX)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     add_kernel<<<cuda_gridsize(N), BLOCK>>>(N, ALPHA, X, INCX);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "add_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
 extern "C" void scal_gpu(int N, float ALPHA, float * X, int INCX)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     scal_kernel<<<cuda_gridsize(N), BLOCK>>>(N, ALPHA, X, INCX);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "scal_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
 extern "C" void supp_gpu(int N, float ALPHA, float * X, int INCX)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     supp_kernel<<<cuda_gridsize(N), BLOCK>>>(N, ALPHA, X, INCX);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "supp_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
 extern "C" void fill_gpu(int N, float ALPHA, float * X, int INCX)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     fill_kernel<<<cuda_gridsize(N), BLOCK>>>(N, ALPHA, X, INCX);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "fill_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -740,7 +989,15 @@ extern "C" void shortcut_gpu(int batch, int w1, int h1, int c1, float *add, int
     if(sample < 1) sample = 1;
 
     int size = batch * minw * minh * minc;
+#ifdef BENCHMARK
+    t = clock();
+#endif
     shortcut_kernel<<<cuda_gridsize(size), BLOCK>>>(size, minw, minh, minc, stride, sample, batch, w1, h1, c1, add, w2, h2, c2, s1, s2, out);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "shortcut_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -763,7 +1020,15 @@ __global__ void smooth_l1_kernel(int n, float *pred, float *truth, float *delta,
 
 extern "C" void smooth_l1_gpu(int n, float *pred, float *truth, float *delta, float *error)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     smooth_l1_kernel<<<cuda_gridsize(n), BLOCK>>>(n, pred, truth, delta, error);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "smooth_l1_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -780,7 +1045,15 @@ __global__ void softmax_x_ent_kernel(int n, float *pred, float *truth, float *de
 
 extern "C" void softmax_x_ent_gpu(int n, float *pred, float *truth, float *delta, float *error)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     softmax_x_ent_kernel<<<cuda_gridsize(n), BLOCK>>>(n, pred, truth, delta, error);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "softmax_x_ent_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -797,7 +1070,15 @@ __global__ void logistic_x_ent_kernel(int n, float *pred, float *truth, float *d
 
 extern "C" void logistic_x_ent_gpu(int n, float *pred, float *truth, float *delta, float *error)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     logistic_x_ent_kernel<<<cuda_gridsize(n), BLOCK>>>(n, pred, truth, delta, error);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "logistic_x_ent_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -813,7 +1094,15 @@ __global__ void l2_kernel(int n, float *pred, float *truth, float *delta, float
 
 extern "C" void l2_gpu(int n, float *pred, float *truth, float *delta, float *error)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     l2_kernel<<<cuda_gridsize(n), BLOCK>>>(n, pred, truth, delta, error);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "l2_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -829,7 +1118,15 @@ __global__ void l1_kernel(int n, float *pred, float *truth, float *delta, float
 
 extern "C" void l1_gpu(int n, float *pred, float *truth, float *delta, float *error)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     l1_kernel<<<cuda_gridsize(n), BLOCK>>>(n, pred, truth, delta, error);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "l1_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -844,7 +1141,15 @@ __global__ void wgan_kernel(int n, float *pred, float *truth, float *delta, floa
 
 extern "C" void wgan_gpu(int n, float *pred, float *truth, float *delta, float *error)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     wgan_kernel<<<cuda_gridsize(n), BLOCK>>>(n, pred, truth, delta, error);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "wgan_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -875,7 +1180,15 @@ __global__ void deinter_kernel(int NX, float *X, int NY, float *Y, int B, float
 
 extern "C" void deinter_gpu(int NX, float *X, int NY, float *Y, int B, float *OUT)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     deinter_kernel<<<cuda_gridsize((NX+NY)*B), BLOCK>>>(NX, X, NY, Y, B, OUT);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "deinter_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -895,13 +1208,29 @@ __global__ void inter_kernel(int NX, float *X, int NY, float *Y, int B, float *O
 
 extern "C" void inter_gpu(int NX, float *X, int NY, float *Y, int B, float *OUT)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     inter_kernel<<<cuda_gridsize((NX+NY)*B), BLOCK>>>(NX, X, NY, Y, B, OUT);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "inter_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
 extern "C" void weighted_sum_gpu(float *a, float *b, float *s, int num, float *c)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     weighted_sum_kernel<<<cuda_gridsize(num), BLOCK>>>(num, a, b, s, c);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "weighted_sum_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -917,7 +1246,15 @@ __global__ void weighted_delta_kernel(int n, float *a, float *b, float *s, float
 
 extern "C" void weighted_delta_gpu(float *a, float *b, float *s, float *da, float *db, float *ds, int num, float *dc)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     weighted_delta_kernel<<<cuda_gridsize(num), BLOCK>>>(num, a, b, s, da, db, ds, dc);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "weighted_delta_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -931,7 +1268,15 @@ __global__ void mult_add_into_kernel(int n, float *a, float *b, float *c)
 
 extern "C" void mult_add_into_gpu(int num, float *a, float *b, float *c)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     mult_add_into_kernel<<<cuda_gridsize(num), BLOCK>>>(num, a, b, c);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "mult_add_into_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -982,7 +1327,15 @@ extern "C" void softmax_tree(float *input, int spatial, int batch, int stride, f
        }
      */
     int num = spatial*batch*hier.groups;
+#ifdef BENCHMARK
+    t = clock();
+#endif
     softmax_tree_kernel<<<cuda_gridsize(num), BLOCK>>>(input, spatial, batch, stride, temp, output, hier.groups, tree_groups_size, tree_groups_offset);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "softmax_tree_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
     cuda_free((float *)tree_groups_size);
     cuda_free((float *)tree_groups_offset);
@@ -999,7 +1352,15 @@ __global__ void softmax_kernel(float *input, int n, int batch, int batch_offset,
 
 extern "C" void softmax_gpu(float *input, int n, int batch, int batch_offset, int groups, int group_offset, int stride, float temp, float *output)
 {
+#ifdef BENCHMARK
+    t = clock();
+#endif
     softmax_kernel<<<cuda_gridsize(batch*groups), BLOCK>>>(input, n, batch, batch_offset, groups, group_offset, stride, temp, output);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "softmax_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -1030,6 +1391,14 @@ __global__ void upsample_kernel(size_t N, float *x, int w, int h, int c, int bat
 extern "C" void upsample_gpu(float *in, int w, int h, int c, int batch, int stride, int forward, float scale, float *out)
 {
     size_t size = w*h*c*batch*stride*stride;
+#ifdef BENCHMARK
+    t = clock();
+#endif
     upsample_kernel<<<cuda_gridsize(size), BLOCK>>>(size, in, w, h, c, batch, stride, forward, scale, out);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "upsample_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
diff --git a/src/col2im_kernels.cu b/src/col2im_kernels.cu
index ba45e0f..1925c74 100644
--- a/src/col2im_kernels.cu
+++ b/src/col2im_kernels.cu
@@ -49,10 +49,18 @@ void col2im_gpu(float *data_col,
     int height_col = (height + 2 * pad - ksize) / stride + 1;
     int width_col = (width + 2 * pad - ksize) / stride + 1;
     int num_kernels = channels * height * width;
+#ifdef BENCHMARK
+    clock_t t;
+    t = clock();
+#endif
     col2im_gpu_kernel<<<(num_kernels+BLOCK-1)/BLOCK,
         BLOCK>>>(
                 num_kernels, data_col, height, width, ksize, pad,
                 stride, height_col,
                 width_col, data_im);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "col2im_gpu_kernel", (int)time_taken);
+#endif
 }
-
diff --git a/src/convolutional_kernels.cu b/src/convolutional_kernels.cu
index 4a1047b..bba33a7 100644
--- a/src/convolutional_kernels.cu
+++ b/src/convolutional_kernels.cu
@@ -22,7 +22,16 @@ __global__ void binarize_kernel(float *x, int n, float *binary)
 
 void binarize_gpu(float *x, int n, float *binary)
 {
+#ifdef BENCHMARK
+    clock_t t;
+    t = clock();
+#endif
     binarize_kernel<<<cuda_gridsize(n), BLOCK>>>(x, n, binary);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "binarize_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -43,7 +52,16 @@ __global__ void binarize_input_kernel(float *input, int n, int size, float *bina
 
 void binarize_input_gpu(float *input, int n, int size, float *binary)
 {
+#ifdef BENCHMARK
+    clock_t t;
+    t = clock();
+#endif
     binarize_input_kernel<<<cuda_gridsize(size), BLOCK>>>(input, n, size, binary);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "binarize_input_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -66,7 +84,16 @@ __global__ void binarize_weights_kernel(float *weights, int n, int size, float *
 
 void binarize_weights_gpu(float *weights, int n, int size, float *binary)
 {
+#ifdef BENCHMARK
+    clock_t t;
+    t = clock();
+#endif
     binarize_weights_kernel<<<cuda_gridsize(n), BLOCK>>>(weights, n, size, binary);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "binarize_weights_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -171,8 +198,16 @@ extern "C" void smooth_layer(layer l, int size, float rate)
     int c = l.out_c;
 
     size_t n = h*w*c*l.batch;
-
+#ifdef BENCHMARK
+    clock_t t;
+    t = clock();
+#endif
     smooth_kernel<<<cuda_gridsize(n), BLOCK>>>(l.output_gpu, n, l.w, l.h, l.c, size, rate, l.delta_gpu);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "smooth_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -326,5 +361,3 @@ void update_convolutional_layer_gpu(layer l, update_args a)
         constrain_gpu(l.nweights, l.clip, l.weights_gpu, 1);
     }
 }
-
-
diff --git a/src/crop_layer_kernels.cu b/src/crop_layer_kernels.cu
index b5b9f55..46730bc 100644
--- a/src/crop_layer_kernels.cu
+++ b/src/crop_layer_kernels.cu
@@ -195,12 +195,32 @@ extern "C" void forward_crop_layer_gpu(crop_layer layer, network net)
 
     int size = layer.batch * layer.w * layer.h;
 
+#ifdef BENCHMARK
+    clock_t t1;
+    t1 = clock();
+#endif
     levels_image_kernel<<<cuda_gridsize(size), BLOCK>>>(net.input_gpu, layer.rand_gpu, layer.batch, layer.w, layer.h, net.train, layer.saturation, layer.exposure, translate, scale, layer.shift);
+#ifdef BENCHMARK
+    t1 = clock() - t1;
+    double time_taken1 = ((double)t1);
+    printf("%s\t%d\n", "levels_image_kernel", (int)time_taken1);
+#endif
+
     check_error(cudaPeekAtLastError());
 
     size = layer.batch*layer.c*layer.out_w*layer.out_h;
 
+#ifdef BENCHMARK
+    clock_t t2;
+    t2 = clock();
+#endif
     forward_crop_layer_kernel<<<cuda_gridsize(size), BLOCK>>>(net.input_gpu, layer.rand_gpu, size, layer.c, layer.h, layer.w, layer.out_h, layer.out_w, net.train, layer.flip, radians, layer.output_gpu);
+#ifdef BENCHMARK
+    t2 = clock() - t2;
+    double time_taken2 = ((double)t2);
+    printf("%s\t%d\n", "forward_crop_layer_kernel", (int)time_taken2);
+#endif
+
     check_error(cudaPeekAtLastError());
 
 /*
@@ -222,4 +242,3 @@ extern "C" void forward_crop_layer_gpu(crop_layer layer, network net)
        cvWaitKey(0);
        */
 }
-
diff --git a/src/cuda.c b/src/cuda.c
index 48aba6e..7e00098 100644
--- a/src/cuda.c
+++ b/src/cuda.c
@@ -152,16 +152,34 @@ void cuda_free(float *x_gpu)
 
 void cuda_push_array(float *x_gpu, float *x, size_t n)
 {
+#ifdef BENCHMARK
+    clock_t t;
+    t = clock();
+#endif
     size_t size = sizeof(float)*n;
     cudaError_t status = cudaMemcpy(x_gpu, x, size, cudaMemcpyHostToDevice);
     check_error(status);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%x\t%d\n", "opencl_push_array", x, (int)time_taken);
+#endif
 }
 
 void cuda_pull_array(float *x_gpu, float *x, size_t n)
 {
+#ifdef BENCHMARK
+    clock_t t;
+    t = clock();
+#endif
     size_t size = sizeof(float)*n;
     cudaError_t status = cudaMemcpy(x, x_gpu, size, cudaMemcpyDeviceToHost);
     check_error(status);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%x\t%d\n", "opencl_pull_array", x, (int)time_taken);
+#endif
 }
 
 float cuda_mag_array(float *x_gpu, size_t n)
diff --git a/src/dropout_layer_kernels.cu b/src/dropout_layer_kernels.cu
index bd12b67..fcfa316 100644
--- a/src/dropout_layer_kernels.cu
+++ b/src/dropout_layer_kernels.cu
@@ -27,7 +27,17 @@ void forward_dropout_layer_gpu(dropout_layer layer, network net)
     cuda_push_array(layer.rand_gpu, layer.rand, size);
     */
 
+#ifdef BENCHMARK
+    clock_t t;
+    t = clock();
+#endif
     yoloswag420blazeit360noscope<<<cuda_gridsize(size), BLOCK>>>(net.input_gpu, size, layer.rand_gpu, layer.probability, layer.scale);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "yoloswag420blazeit360noscope", (int)time_taken);
+#endif
+
     check_error(cudaPeekAtLastError());
 }
 
@@ -36,6 +46,16 @@ void backward_dropout_layer_gpu(dropout_layer layer, network net)
     if(!net.delta_gpu) return;
     int size = layer.inputs*layer.batch;
 
+#ifdef BENCHMARK
+    clock_t t;
+    t = clock();
+#endif
     yoloswag420blazeit360noscope<<<cuda_gridsize(size), BLOCK>>>(net.delta_gpu, size, layer.rand_gpu, layer.probability, layer.scale);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "yoloswag420blazeit360noscope", (int)time_taken);
+#endif
+
     check_error(cudaPeekAtLastError());
 }
diff --git a/src/gemm.c b/src/gemm.c
index 648027f..087671a 100644
--- a/src/gemm.c
+++ b/src/gemm.c
@@ -175,10 +175,21 @@ void gemm_gpu(int TA, int TB, int M, int N, int K, float ALPHA,
         float BETA,
         float *C_gpu, int ldc)
 {
+#ifdef BENCHMARK
+    clock_t t;
+    t = clock();
+#endif
+
     cublasHandle_t handle = blas_handle();
     cudaError_t status = cublasSgemm(handle, (TB ? CUBLAS_OP_T : CUBLAS_OP_N), 
             (TA ? CUBLAS_OP_T : CUBLAS_OP_N), N, M, K, &ALPHA, B_gpu, ldb, A_gpu, lda, &BETA, C_gpu, ldc);
     check_error(status);
+
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "cublasSgemm", (int)time_taken);
+#endif
 }
 
 #include <stdio.h>
diff --git a/src/im2col_kernels.cu b/src/im2col_kernels.cu
index 07b5e67..447c72c 100644
--- a/src/im2col_kernels.cu
+++ b/src/im2col_kernels.cu
@@ -53,9 +53,18 @@ void im2col_gpu(float *im,
     int height_col = (height + 2 * pad - ksize) / stride + 1;
     int width_col = (width + 2 * pad - ksize) / stride + 1;
     int num_kernels = channels * height_col * width_col;
+#ifdef BENCHMARK
+    clock_t t;
+    t = clock();
+#endif
     im2col_gpu_kernel<<<(num_kernels+BLOCK-1)/BLOCK,
         BLOCK>>>(
                 num_kernels, im, height, width, ksize, pad,
                 stride, height_col,
                 width_col, data_col);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "im2col_gpu_kernel", (int)time_taken);
+#endif
 }
diff --git a/src/maxpool_layer_kernels.cu b/src/maxpool_layer_kernels.cu
index 869ef46..ab0d198 100644
--- a/src/maxpool_layer_kernels.cu
+++ b/src/maxpool_layer_kernels.cu
@@ -92,7 +92,16 @@ extern "C" void forward_maxpool_layer_gpu(maxpool_layer layer, network net)
 
     size_t n = h*w*c*layer.batch;
 
+#ifdef BENCHMARK
+    clock_t t;
+    t = clock();
+#endif
     forward_maxpool_layer_kernel<<<cuda_gridsize(n), BLOCK>>>(n, layer.h, layer.w, layer.c, layer.stride, layer.size, layer.pad, net.input_gpu, layer.output_gpu, layer.indexes_gpu);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "forward_maxpool_layer_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
@@ -100,7 +109,16 @@ extern "C" void backward_maxpool_layer_gpu(maxpool_layer layer, network net)
 {
     size_t n = layer.h*layer.w*layer.c*layer.batch;
 
+#ifdef BENCHMARK
+    clock_t t;
+    t = clock();
+#endif
     backward_maxpool_layer_kernel<<<cuda_gridsize(n), BLOCK>>>(n, layer.h, layer.w, layer.c, layer.stride, layer.size, layer.pad, layer.delta_gpu, net.delta_gpu, layer.indexes_gpu);
+#ifdef BENCHMARK
+    t = clock() - t;
+    double time_taken = ((double)t);
+    printf("%s\t%d\n", "backward_maxpool_layer_kernel", (int)time_taken);
+#endif
     check_error(cudaPeekAtLastError());
 }
 
diff --git a/src/network.c b/src/network.c
index aaab799..e186b90 100644
--- a/src/network.c
+++ b/src/network.c
@@ -775,7 +775,17 @@ void forward_network_gpu(network *netp)
         if(l.delta_gpu){
             fill_gpu(l.outputs * l.batch, 0, l.delta_gpu, 1);
         }
+#ifdef BENCHMARK
+        clock_t t;
+        t = clock();
+#endif
         l.forward_gpu(l, net);
+#ifdef BENCHMARK
+        t = clock() - t;
+        double time_taken = ((double)t);
+        const char* layerName[] = { "CONVOLUTIONAL","DECONVOLUTIONAL","CONNECTED", "MAXPOOL", "SOFTMAX", "DETECTION", "DROPOUT", "CROP", "ROUTE", "COST", "NORMALIZATION", "AVGPOOL", "LOCAL", "SHORTCUT", "ACTIVE", "RNN", "GRU", "LSTM", "CRNN", "BATCHNORM", "NETWORK", "XNOR", "REGION", "YOLO", "ISEG", "REORG", "UPSAMPLE", "LOGXENT", "L2NORM", "BLANK"};
+        printf("FW %s\t%d\n", layerName[(int)l.type], (int)time_taken);
+#endif
         net.input_gpu = l.output_gpu;
         net.input = l.output;
         if(l.truth) {
@@ -806,7 +816,17 @@ void backward_network_gpu(network *netp)
             net.delta_gpu = prev.delta_gpu;
         }
         net.index = i;
+#ifdef BENCHMARK
+        clock_t t;
+        t = clock();
+#endif
         l.backward_gpu(l, net);
+#ifdef BENCHMARK
+        t = clock() - t;
+        double time_taken = ((double)t);
+        const char* layerName[] = { "CONVOLUTIONAL","DECONVOLUTIONAL","CONNECTED", "MAXPOOL", "SOFTMAX", "DETECTION", "DROPOUT", "CROP", "ROUTE", "COST", "NORMALIZATION", "AVGPOOL", "LOCAL", "SHORTCUT", "ACTIVE", "RNN", "GRU", "LSTM", "CRNN", "BATCHNORM", "NETWORK", "XNOR", "REGION", "YOLO", "ISEG", "REORG", "UPSAMPLE", "LOGXENT", "L2NORM", "BLANK"};
+        printf("BW %s\t%d\n", layerName[(int)l.type], (int)time_taken);
+#endif
     }
 }
 
@@ -830,7 +850,17 @@ void update_network_gpu(network *netp)
     for(i = 0; i < net.n; ++i){
         layer l = net.layers[i];
         if(l.update_gpu){
-            l.update_gpu(l, a);
+#ifdef BENCHMARK
+        clock_t t;
+        t = clock();
+#endif
+        l.update_gpu(l, a);
+#ifdef BENCHMARK
+        t = clock() - t;
+        double time_taken = ((double)t);
+        const char* layerName[] = { "CONVOLUTIONAL","DECONVOLUTIONAL","CONNECTED", "MAXPOOL", "SOFTMAX", "DETECTION", "DROPOUT", "CROP", "ROUTE", "COST", "NORMALIZATION", "AVGPOOL", "LOCAL", "SHORTCUT", "ACTIVE", "RNN", "GRU", "LSTM", "CRNN", "BATCHNORM", "NETWORK", "XNOR", "REGION", "YOLO", "ISEG", "REORG", "UPSAMPLE", "LOGXENT", "L2NORM", "BLANK"};
+        printf("UP %s\t%d\n", layerName[(int)l.type], (int)time_taken);
+#endif
         }
     }
 }
diff --git a/src/parser.c b/src/parser.c
index c8141c9..33c7918 100644
--- a/src/parser.c
+++ b/src/parser.c
@@ -1011,7 +1011,7 @@ void save_weights_upto(network *net, char *filename, int cutoff)
         cuda_set_device(net->gpu_index);
     }
 #endif
-    fprintf(stderr, "Saving weights to %s\n", filename);
+    //fprintf(stderr, "Saving weights to %s\n", filename);
     FILE *fp = fopen(filename, "wb");
     if(!fp) file_error(filename);
 
@@ -1301,7 +1301,7 @@ void load_weights_upto(network *net, char *filename, int start, int cutoff)
 #endif
         }
     }
-    fprintf(stderr, "Done!\n");
+    //fprintf(stderr, "Done!\n");
     fclose(fp);
 }
 
diff --git a/src/region_layer.c b/src/region_layer.c
index 179f5e3..b9018a0 100644
--- a/src/region_layer.c
+++ b/src/region_layer.c
@@ -317,7 +317,7 @@ void forward_region_layer(const layer l, network net)
         }
     }
     *(l.cost) = pow(mag_array(l.delta, l.outputs * l.batch), 2);
-    printf("Region Avg IOU: %f, Class: %f, Obj: %f, No Obj: %f, Avg Recall: %f,  count: %d\n", avg_iou/count, avg_cat/class_count, avg_obj/count, avg_anyobj/(l.w*l.h*l.n*l.batch), recall/count, count);
+    //printf("Region Avg IOU: %f, Class: %f, Obj: %f, No Obj: %f, Avg Recall: %f,  count: %d\n", avg_iou/count, avg_cat/class_count, avg_obj/count, avg_anyobj/(l.w*l.h*l.n*l.batch), recall/count, count);
 }
 
 void backward_region_layer(const layer l, network net)
diff --git a/src/yolo_layer.c b/src/yolo_layer.c
index c338036..ab0dd80 100644
--- a/src/yolo_layer.c
+++ b/src/yolo_layer.c
@@ -236,7 +236,7 @@ void forward_yolo_layer(const layer l, network net)
         }
     }
     *(l.cost) = pow(mag_array(l.delta, l.outputs * l.batch), 2);
-    printf("Region %d Avg IOU: %f, Class: %f, Obj: %f, No Obj: %f, .5R: %f, .75R: %f,  count: %d\n", net.index, avg_iou/count, avg_cat/class_count, avg_obj/count, avg_anyobj/(l.w*l.h*l.n*l.batch), recall/count, recall75/count, count);
+    //printf("Region %d Avg IOU: %f, Class: %f, Obj: %f, No Obj: %f, .5R: %f, .75R: %f,  count: %d\n", net.index, avg_iou/count, avg_cat/class_count, avg_obj/count, avg_anyobj/(l.w*l.h*l.n*l.batch), recall/count, recall75/count, count);
 }
 
 void backward_yolo_layer(const layer l, network net)
